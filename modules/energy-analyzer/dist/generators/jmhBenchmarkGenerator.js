"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.extractMethodsFromReports = extractMethodsFromReports;
exports.generateJMHBenchmarkClass = generateJMHBenchmarkClass;
exports.generateCustomBenchmarkRunner = generateCustomBenchmarkRunner;
exports.generateMavenPom = generateMavenPom;
exports.saveBenchmarkProject = saveBenchmarkProject;
// src/generators/jmhBenchmarkGenerator.ts
const fs_1 = __importDefault(require("fs"));
const path_1 = __importDefault(require("path"));
/**
 * Extract method information from AST reports
 */
function extractMethodsFromReports(reports) {
    const methods = [];
    for (const report of reports) {
        methods.push({
            className: report.className,
            methodName: report.methodName,
            parameters: report.parameters || [],
            returnType: report.returnType || "void",
            isStatic: report.isStatic || false
        });
    }
    return methods;
}
/**
 * Generate JMH benchmark Java code
 */
function generateJMHBenchmarkClass(methods, packageName = "com.greencode.benchmarks") {
    const classNames = [...new Set(methods.map(m => m.className))];
    let code = `package ${packageName};

import org.openjdk.jmh.annotations.*;
import org.openjdk.jmh.runner.Runner;
import org.openjdk.jmh.runner.RunnerException;
import org.openjdk.jmh.runner.options.Options;
import org.openjdk.jmh.runner.options.OptionsBuilder;
import org.openjdk.jmh.infra.Blackhole;

import java.util.concurrent.TimeUnit;

/**
 * Auto-generated JMH Benchmarks for Energy Analysis
 * Generated at: ${new Date().toISOString()}
 */
@BenchmarkMode(Mode.AverageTime)
@OutputTimeUnit(TimeUnit.MILLISECONDS)
@State(Scope.Thread)
@Warmup(iterations = 3, time = 1, timeUnit = TimeUnit.SECONDS)
@Measurement(iterations = 5, time = 1, timeUnit = TimeUnit.SECONDS)
@Fork(1)
public class AutoGeneratedBenchmark {

`;
    // Add instance variables for each class
    for (const className of classNames) {
        code += `    private ${className} ${className.toLowerCase()}Instance;\n`;
    }
    code += `\n    @Setup\n`;
    code += `    public void setup() {\n`;
    // Initialize instances
    for (const className of classNames) {
        code += `        ${className.toLowerCase()}Instance = new ${className}();\n`;
    }
    code += `    }\n\n`;
    // Generate benchmark methods
    for (const method of methods) {
        const instanceVar = method.className.toLowerCase() + "Instance";
        const benchmarkName = `benchmark_${method.className}_${method.methodName}`;
        code += `    @Benchmark\n`;
        code += `    public void ${benchmarkName}(Blackhole blackhole) {\n`;
        // Generate method call with sample parameters
        const params = generateSampleParameters(method.parameters);
        const methodCall = method.isStatic
            ? `${method.className}.${method.methodName}(${params})`
            : `${instanceVar}.${method.methodName}(${params})`;
        if (method.returnType !== "void") {
            code += `        ${method.returnType} result = ${methodCall};\n`;
            code += `        blackhole.consume(result);\n`;
        }
        else {
            code += `        ${methodCall};\n`;
        }
        code += `    }\n\n`;
    }
    // Add main method to run benchmarks
    code += `    public static void main(String[] args) throws RunnerException {
        Options opt = new OptionsBuilder()
                .include(AutoGeneratedBenchmark.class.getSimpleName())
                .build();
        new Runner(opt).run();
    }
}
`;
    return code;
}
/**
 * Generate sample parameters for method calls
 */
function generateSampleParameters(parameters) {
    if (parameters.length === 0)
        return "";
    return parameters.map(param => {
        const type = param.type.toLowerCase();
        // Generate reasonable default values
        if (type.includes("int"))
            return "42";
        if (type.includes("long"))
            return "42L";
        if (type.includes("double"))
            return "42.0";
        if (type.includes("float"))
            return "42.0f";
        if (type.includes("boolean"))
            return "true";
        if (type.includes("string"))
            return '"test"';
        if (type.includes("char"))
            return "'a'";
        if (type.includes("byte"))
            return "(byte)42";
        if (type.includes("short"))
            return "(short)42";
        // For arrays
        if (type.includes("[]")) {
            const baseType = type.replace("[]", "");
            return `new ${baseType}[]{${generateSampleParameters([{ name: "", type: baseType }])}}`;
        }
        // For objects, try to create with default constructor
        return `new ${param.type}()`;
    }).join(", ");
}
/**
 * Generate custom benchmark runner that outputs JSON
 */
function generateCustomBenchmarkRunner(methods, packageName = "com.greencode.benchmarks") {
    const classNames = [...new Set(methods.map(m => m.className))];
    let code = `package ${packageName};

import java.io.FileWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import com.google.gson.Gson;
import com.google.gson.GsonBuilder;

/**
 * Custom Benchmark Runner - Outputs JSON for Energy Analysis
 * Generated at: ${new Date().toISOString()}
 */
public class CustomBenchmarkRunner {

    public static class BenchmarkResult {
        public String className;
        public String methodName;
        public double medianMs;
        public double meanMs;
        public double p95Ms;
        public double minMs;
        public double maxMs;
        public double stdDev;
        public int runs;
        public String benchmarkTool = "CustomRunner";
    }

    private static final int WARMUP_ITERATIONS = 10;
    private static final int MEASUREMENT_ITERATIONS = 100;

`;
    // Add instance variables
    for (const className of classNames) {
        code += `    private ${className} ${className.toLowerCase()}Instance = new ${className}();\n`;
    }
    code += `\n    public List<BenchmarkResult> runAllBenchmarks() {\n`;
    code += `        List<BenchmarkResult> results = new ArrayList<>();\n\n`;
    // Generate benchmark calls for each method
    for (const method of methods) {
        const instanceVar = method.className.toLowerCase() + "Instance";
        const params = generateSampleParameters(method.parameters);
        const methodCall = method.isStatic
            ? `${method.className}.${method.methodName}(${params})`
            : `${instanceVar}.${method.methodName}(${params})`;
        code += `        // Benchmark: ${method.className}.${method.methodName}\n`;
        code += `        results.add(benchmark_${method.className}_${method.methodName}());\n\n`;
    }
    code += `        return results;\n`;
    code += `    }\n\n`;
    // Generate individual benchmark methods
    for (const method of methods) {
        const instanceVar = method.className.toLowerCase() + "Instance";
        const params = generateSampleParameters(method.parameters);
        const methodCall = method.isStatic
            ? `${method.className}.${method.methodName}(${params})`
            : `${instanceVar}.${method.methodName}(${params})`;
        code += `    private BenchmarkResult benchmark_${method.className}_${method.methodName}() {
        List<Long> times = new ArrayList<>();
        
        // Warmup
        for (int i = 0; i < WARMUP_ITERATIONS; i++) {
            ${methodCall};
        }
        
        // Measurement
        for (int i = 0; i < MEASUREMENT_ITERATIONS; i++) {
            long start = System.nanoTime();
            ${methodCall};
            long end = System.nanoTime();
            times.add(end - start);
        }
        
        // Calculate statistics
        times.sort(Long::compareTo);
        double mean = times.stream().mapToLong(Long::longValue).average().orElse(0.0) / 1_000_000.0;
        double median = times.get(times.size() / 2) / 1_000_000.0;
        double min = times.get(0) / 1_000_000.0;
        double max = times.get(times.size() - 1) / 1_000_000.0;
        double p95 = times.get((int)(times.size() * 0.95)) / 1_000_000.0;
        
        // Standard deviation
        double variance = times.stream()
            .mapToDouble(t -> Math.pow((t / 1_000_000.0) - mean, 2))
            .average().orElse(0.0);
        double stdDev = Math.sqrt(variance);
        
        BenchmarkResult result = new BenchmarkResult();
        result.className = "${method.className}";
        result.methodName = "${method.methodName}";
        result.medianMs = median;
        result.meanMs = mean;
        result.p95Ms = p95;
        result.minMs = min;
        result.maxMs = max;
        result.stdDev = stdDev;
        result.runs = MEASUREMENT_ITERATIONS;
        
        System.out.printf("‚úì %s.%s: %.3f ms (median)%n", 
            result.className, result.methodName, result.medianMs);
        
        return result;
    }

`;
    }
    // Add main method
    code += `    public static void main(String[] args) {
        System.out.println("üöÄ Starting Custom Benchmark Runner...");
        System.out.println("Warmup iterations: " + WARMUP_ITERATIONS);
        System.out.println("Measurement iterations: " + MEASUREMENT_ITERATIONS);
        System.out.println();
        
        CustomBenchmarkRunner runner = new CustomBenchmarkRunner();
        List<BenchmarkResult> results = runner.runAllBenchmarks();
        
        // Save to JSON
        String outputFile = "benchmark-results.json";
        try {
            Gson gson = new GsonBuilder().setPrettyPrinting().create();
            FileWriter writer = new FileWriter(outputFile);
            gson.toJson(results, writer);
            writer.close();
            System.out.println();
            System.out.println("‚úÖ Benchmark results saved to: " + outputFile);
            System.out.println("üìä Total methods benchmarked: " + results.size());
        } catch (IOException e) {
            System.err.println("‚ùå Failed to save results: " + e.getMessage());
            e.printStackTrace();
        }
    }
}
`;
    return code;
}
/**
 * Generate Maven pom.xml for JMH benchmarks
 */
function generateMavenPom(packageName = "com.greencode.benchmarks") {
    return `<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 
         http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>${packageName}</groupId>
    <artifactId>energy-benchmarks</artifactId>
    <version>1.0-SNAPSHOT</version>

    <properties>
        <maven.compiler.source>11</maven.compiler.source>
        <maven.compiler.target>11</maven.compiler.target>
        <jmh.version>1.37</jmh.version>
        <gson.version>2.10.1</gson.version>
    </properties>

    <dependencies>
        <!-- JMH Core -->
        <dependency>
            <groupId>org.openjdk.jmh</groupId>
            <artifactId>jmh-core</artifactId>
            <version>\${jmh.version}</version>
        </dependency>
        
        <!-- JMH Annotation Processor -->
        <dependency>
            <groupId>org.openjdk.jmh</groupId>
            <artifactId>jmh-generator-annprocess</artifactId>
            <version>\${jmh.version}</version>
            <scope>provided</scope>
        </dependency>
        
        <!-- Gson for JSON output -->
        <dependency>
            <groupId>com.google.code.gson</groupId>
            <artifactId>gson</artifactId>
            <version>\${gson.version}</version>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-shade-plugin</artifactId>
                <version>3.5.0</version>
                <executions>
                    <execution>
                        <phase>package</phase>
                        <goals>
                            <goal>shade</goal>
                        </goals>
                        <configuration>
                            <finalName>benchmarks</finalName>
                            <transformers>
                                <transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">
                                    <mainClass>org.openjdk.jmh.Main</mainClass>
                                </transformer>
                            </transformers>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>
</project>`;
}
/**
 * Save generated benchmark files to disk
 */
function saveBenchmarkProject(methods, outputDir, packageName = "com.greencode.benchmarks") {
    // Create directory structure
    const srcDir = path_1.default.join(outputDir, "src", "main", "java", ...packageName.split("."));
    fs_1.default.mkdirSync(srcDir, { recursive: true });
    // Generate and save JMH benchmark
    const jmhCode = generateJMHBenchmarkClass(methods, packageName);
    const jmhFile = path_1.default.join(srcDir, "AutoGeneratedBenchmark.java");
    fs_1.default.writeFileSync(jmhFile, jmhCode);
    console.log(`‚úÖ Generated JMH benchmark: ${jmhFile}`);
    // Generate and save custom runner
    const customCode = generateCustomBenchmarkRunner(methods, packageName);
    const customFile = path_1.default.join(srcDir, "CustomBenchmarkRunner.java");
    fs_1.default.writeFileSync(customFile, customCode);
    console.log(`‚úÖ Generated custom runner: ${customFile}`);
    // Generate and save pom.xml
    const pomXml = generateMavenPom(packageName);
    const pomFile = path_1.default.join(outputDir, "pom.xml");
    fs_1.default.writeFileSync(pomFile, pomXml);
    console.log(`‚úÖ Generated Maven pom.xml: ${pomFile}`);
    // Generate README
    const readme = generateReadme(packageName);
    const readmeFile = path_1.default.join(outputDir, "README.md");
    fs_1.default.writeFileSync(readmeFile, readme);
    console.log(`‚úÖ Generated README: ${readmeFile}`);
    console.log(`\nüì¶ Benchmark project created in: ${outputDir}`);
    console.log(`\nüìñ Next steps:`);
    console.log(`   1. cd ${outputDir}`);
    console.log(`   2. mvn clean package`);
    console.log(`   3. java -cp target/benchmarks.jar ${packageName}.CustomBenchmarkRunner`);
    console.log(`   4. Use benchmark-results.json with your energy analyzer`);
}
function generateReadme(packageName) {
    return `# Auto-Generated Energy Benchmarks

This project contains automatically generated benchmarks for energy analysis.

## Running Benchmarks

### Option 1: Custom Runner (Recommended for Energy Analysis)
\`\`\`bash
# Build the project
mvn clean package

# Run custom benchmark runner (outputs JSON)
java -cp target/benchmarks.jar ${packageName}.CustomBenchmarkRunner

# Results will be saved to: benchmark-results.json
\`\`\`

### Option 2: JMH Runner (More detailed metrics)
\`\`\`bash
# Build the project
mvn clean package

# Run JMH benchmarks
java -jar target/benchmarks.jar

# To get JSON output:
java -jar target/benchmarks.jar -rf json -rff jmh-results.json
\`\`\`

## Using Results with Energy Analyzer

After running benchmarks, use the JSON output with your energy analyzer:

\`\`\`bash
greencode-energy-analyze -A ast/ -c cfg/ -b benchmark-results.json
\`\`\`

## Customizing Benchmarks

You can modify the generated benchmark files:
- \`AutoGeneratedBenchmark.java\` - JMH-based benchmarks
- \`CustomBenchmarkRunner.java\` - Simple custom runner

### Adjusting Parameters
Edit the \`@Setup\` method in \`AutoGeneratedBenchmark.java\` to provide realistic test data.

### Adjusting Iterations
In \`CustomBenchmarkRunner.java\`:
- \`WARMUP_ITERATIONS\` - Number of warmup runs (default: 10)
- \`MEASUREMENT_ITERATIONS\` - Number of measured runs (default: 100)

## Dependencies
- Java 11+
- Maven 3.6+
- JMH 1.37
- Gson 2.10.1
`;
}
